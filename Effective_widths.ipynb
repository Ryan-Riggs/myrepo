{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Effective_widths.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3xY1dS62ifa8AucpDs4a8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryan-Riggs/myrepo/blob/master/Effective_widths.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWcNMryEc-t0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9CDOD9ttRal",
        "outputId": "194d7ae4-55bb-4e17-bc70-e1a70afc7101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=x05fRJYcgenFzicWB7bzo2lkddjr1IXE4XsJsI-DDyg&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AfDhmrjpttTguzSi-jvgeLUS8o6LK-PeD3fUGsNJA27gSPdriNtrGgTXodY\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac059yoFteQB"
      },
      "source": [
        "\n",
        "x = 'users/eeProject/RivWidthCloudPaper:functions_Landsat578/functions_waterClassification_Jones2019.py'\n",
        "fls = 'users/eeProject/RivWidthCloudPaper:functions_Landsat578/functions_landsat.py'\n",
        "flsh = 'users/eeProject/RivWidthCloudPaper:rwc_landsat.py'\n",
        "fnsLandsat = 'users/eeProject/RivWidthCloudPaper:functions_Landsat578/functions_landsat.py'\n",
        "lsFun = 'users/eeProject/RivWidthCloudPaper:functions_Landsat578/functions_landsat.py'\n",
        "riverFun = 'users/eeProject/RivWidthCloudPaper:functions_river.py'\n",
        "grwl_cline = ee.FeatureCollection('users/eeProject/GRWL_summaryStats')\n",
        "#fc_3spc = ee.FeatureCollection(\"users/rriggs/east_validation_1spc_3x/eastern_merged\")\n",
        "fc_3spc = ee.FeatureCollection(\"users/rriggs/SA_sj_min_100\") ##South America. \n",
        "fc_3spc = ee.FeatureCollection(\"users/rriggs/na_sj_using_R_min_100\")\n",
        "gauges = ee.FeatureCollection(\"users/rriggs/Gauge_points\") ##USGS Gauges \n",
        "#gauges = ee.FeatureCollection(\"users/rriggs/South_AM_100m_stationid\")\n",
        "#fc_3spc = ee.FeatureCollection(\"users/rriggs/Africa_min_100min_3x_1spc\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qqbhTQ0tg-L"
      },
      "source": [
        "jrcSummary = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\")\n",
        "occ = jrcSummary.select('occurrence')\n",
        "jrcMeta = ee.Image(\"JRC/GSW1_0/Metadata\")\n",
        "nobs = jrcMeta.select('valid_obs')\n",
        "change = jrcSummary.select('change_abs')\n",
        "change = change.abs()\n",
        "waterMax = occ.gte(0)\n",
        "grwl = ee.FeatureCollection(\"users/eeProject/grwl\")\n",
        "# create image with bands ranging from quantile 0-100\n",
        "quantileBreaks = ee.List.sequence(0, 100, 1)\n",
        "import folium\n",
        "def creatQuantileImage(l, prev):\n",
        "    return(ee.Image(prev).addBands(occ.gte(ee.Image.constant(l)).rename([ee.String('q').cat(ee.Number(l).format('%03d'))])))\n",
        "\n",
        "\n",
        "# rename the flags so that their value won't be replaced in the next step\n",
        "# when calculating the mean river mask values\n",
        "def appendStringFlag(l):\n",
        "    return(ee.String(l).cat('_flag'))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc4cPzGBuCYt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiBCtIiVPx2b"
      },
      "source": [
        "def Mndwi(image):\n",
        "    return(image.normalizedDifference(['Green', 'Swir1']).rename('mndwi'))\n",
        "\n",
        "def Mbsrv(image):\n",
        "    return(image.select(['Green']).add(image.select(['Red'])).rename('mbsrv'))\n",
        "\n",
        "def Mbsrn(image):\n",
        "    return(image.select(['Nir']).add(image.select(['Swir1'])).rename('mbsrn'))\n",
        "\n",
        "def Ndvi(image):\n",
        "    return(image.normalizedDifference(['Nir', 'Red']).rename('ndvi'))\n",
        "\n",
        "def Awesh(image):\n",
        "    return(image.expression('Blue + 2.5 * Green + (-1.5) * mbsrn + (-0.25) * Swir2', {\n",
        "    'Blue': image.select(['Blue']),\n",
        "    'Green': image.select(['Green']),\n",
        "    'mbsrn': Mbsrn(image).select(['mbsrn']),\n",
        "    'Swir2': image.select(['Swir2'])}))\n",
        "\n",
        "def Dswe(i):\n",
        "    mndwi = Mndwi(i)\n",
        "    mbsrv = Mbsrv(i)\n",
        "    mbsrn = Mbsrn(i)\n",
        "    awesh = Awesh(i)\n",
        "    swir1 = i.select(['Swir1'])\n",
        "    nir = i.select(['Nir'])\n",
        "    ndvi = Ndvi(i)\n",
        "    blue = i.select(['Blue'])\n",
        "    swir2 = i.select(['Swir2'])\n",
        "\n",
        "    t1 = mndwi.gt(0.124)\n",
        "    t2 = mbsrv.gt(mbsrn)\n",
        "    t3 = awesh.gt(0)\n",
        "    t4 = (mndwi.gt(-0.44)\n",
        "    .And(swir1.lt(900))\n",
        "    .And(nir.lt(1500))\n",
        "    .And(ndvi.lt(0.7)))\n",
        "    t5 = (mndwi.gt(-0.5)\n",
        "    .And(blue.lt(1000))\n",
        "    .And(swir1.lt(3000))\n",
        "    .And(swir2.lt(1000))\n",
        "    .And(nir.lt(2500)))\n",
        "\n",
        "    t = t1.add(t2.multiply(10)).add(t3.multiply(100)).add(t4.multiply(1000)).add(t5.multiply(10000))\n",
        "\n",
        "    noWater = (t.eq(0)\n",
        "    .Or(t.eq(1))\n",
        "    .Or(t.eq(10))\n",
        "    .Or(t.eq(100))\n",
        "    .Or(t.eq(1000)))\n",
        "    hWater = (t.eq(1111)\n",
        "    .Or(t.eq(10111))\n",
        "    .Or(t.eq(11011))\n",
        "    .Or(t.eq(11101))\n",
        "    .Or(t.eq(11110))\n",
        "    .Or(t.eq(11111)))\n",
        "    mWater = (t.eq(111)\n",
        "    .Or(t.eq(1011))\n",
        "    .Or(t.eq(1101))\n",
        "    .Or(t.eq(1110))\n",
        "    .Or(t.eq(10011))\n",
        "    .Or(t.eq(10101))\n",
        "    .Or(t.eq(10110))\n",
        "    .Or(t.eq(11001))\n",
        "    .Or(t.eq(11010))\n",
        "    .Or(t.eq(11100)))\n",
        "    pWetland = t.eq(11000)\n",
        "    lWater = (t.eq(11)\n",
        "    .Or(t.eq(101))\n",
        "    .Or(t.eq(110))\n",
        "    .Or(t.eq(1001))\n",
        "    .Or(t.eq(1010))\n",
        "    .Or(t.eq(1100))\n",
        "    .Or(t.eq(10000))\n",
        "    .Or(t.eq(10001))\n",
        "    .Or(t.eq(10010))\n",
        "    .Or(t.eq(10100)))\n",
        "\n",
        "    iDswe = (noWater.multiply(0)\n",
        "    .add(hWater.multiply(1))\n",
        "    .add(mWater.multiply(2))\n",
        "    .add(pWetland.multiply(3))\n",
        "    .add(lWater.multiply(4)))\n",
        "\n",
        "    return(iDswe.rename(['dswe']))\n",
        "\n",
        "def ClassifyWaterJones2019(img):\n",
        "    dswe = Dswe(img)\n",
        "    waterMask = dswe.eq(1).Or(dswe.eq(2)).rename(['waterMask'])\n",
        "    return(waterMask)\n",
        "\n",
        "def switchGeometryLine2Endpoints(f):\n",
        "        f = f.set({'lineGeometry': f.geometry()})\n",
        "        l = f.geometry().coordinates()\n",
        "        g = ee.Geometry.MultiPoint(l, 'EPSG:4326')\n",
        "        return(f.setGeometry(g))\n",
        "\n",
        "def switchGeometryEndpoints2Line(f):\n",
        "        return(f.setGeometry(f.get('lineGeometry')).set('lineGeometry', None))\n",
        "\n",
        "def GetCenterline(clDataset, bound):\n",
        "    # // filter the GRWL centerline based on area of interest\n",
        "    cl = clDataset.filterBounds(bound)\n",
        "    return(cl)\n",
        "\n",
        "def ExtractChannel(image):\n",
        "    # // extract the channel water bodies from the water mask, based on connectivity to the reference centerline.\n",
        "    connectedToCl = (image.Not().cumulativeCost(\n",
        "        source = ee.Image().toByte().paint(grwl_cline, 1).And(image), #// only use the centerline that overlaps with the water mask\n",
        "        maxDistance = 4000,\n",
        "        geodeticDistance = False).eq(0))\n",
        "\n",
        "    channel = image.updateMask(connectedToCl).unmask(0).updateMask(image.gte(0)).rename(['channelMask'])\n",
        "    return(channel)\n",
        "\n",
        "\n",
        "def RemoveIsland(channel):\n",
        "    # /* fill in island as water if the size (number of pixels) of the island is smaller than FILL_SIZE */\n",
        "    fill = channel.Not().selfMask().connectedPixelCount(333).lt(333)\n",
        "    river = channel.where(fill, ee.Image(1)).rename(['riverMask'])\n",
        "    return(river)\n",
        "\n",
        "def ExtractRiver(imgIn, clData, maxDist, minIslandRemoval):\n",
        "    waterMask = imgIn.select(['waterMask'])\n",
        "    bound = waterMask.geometry()\n",
        "    cl = GetCenterline(clData, bound)\n",
        "    channelMask = ExtractChannel(waterMask, cl, maxDist)\n",
        "    riverMask = RemoveIsland(channelMask, minIslandRemoval)\n",
        "    return(imgIn.addBands(channelMask).addBands(riverMask))\n",
        "\n",
        "def widths(image):\n",
        "  width = (image.eq(1).reduceRegions(\n",
        "  collection = filt, \n",
        "  reducer= ee.Reducer.mean(),\n",
        "  ))\n",
        "  flags = (image.reduceRegions(\n",
        "  collection= width.map(switchGeometryLine2Endpoints), \n",
        "  reducer= ee.Reducer.max(),\n",
        "))\n",
        "  return(flags)\n",
        "\n",
        "\n",
        "def filt_lines (f):\n",
        "  return f.set('geo_type', f.geometry().type())\n",
        "\n",
        "def maximum_no_of_tasks(MaxNActive, waitingPeriod):\n",
        "\t\"\"\"maintain a maximum number of active tasks\n",
        "\t\"\"\"\n",
        "\timport time\n",
        "\timport ee\n",
        "\tee.Initialize()\n",
        "\n",
        "\ttime.sleep(10)\n",
        "\t## initialize submitting jobs\n",
        "\tts = list(ee.batch.Task.list())\n",
        "\n",
        "\tNActive = 0\n",
        "\tfor task in ts:\n",
        "\t\tif ('RUNNING' in str(task) or 'READY' in str(task)):\n",
        "\t\t\tNActive += 1\n",
        "\t## wait if the number of current active tasks reach the maximum number\n",
        "\t## defined in MaxNActive\n",
        "\twhile (NActive >= MaxNActive):\n",
        "\t\ttime.sleep(waitingPeriod) # if reach or over maximum no. of active tasks, wait for 2min and check again\n",
        "\t\tts = list(ee.batch.Task.list())\n",
        "\t\tNActive = 0\n",
        "\t\tfor task in ts:\n",
        "\t\t\tif ('RUNNING' in str(task) or 'READY' in str(task)):\n",
        "\t\t\t\tNActive += 1\n",
        "\treturn()\n",
        " \n",
        " ##changed to 2000 from 5000\n",
        "def buffer_zone (f):\n",
        "  return f.buffer(2000)\n",
        "def  ftr_coll (f):\n",
        "  return ee.FeatureCollection(f)\n",
        "\n",
        "def distance_fun (f):\n",
        "  l = f.geometry().distance(filter_gauge.geometry())\n",
        "  d = f.set('distance', l)\n",
        "  return(d)\n",
        "\n",
        "def distance_fun_poly (f):\n",
        "  l = f.geometry().distance(far.geometry())\n",
        "  d = f.set('distance_1', l)\n",
        "  return(d)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BivwrNdKp5_f"
      },
      "source": [
        "riverMask = ExtractChannel(waterMax)\n",
        "quantileImage = ee.Image(quantileBreaks.iterate(creatQuantileImage, ee.Image())).select('^q.*').updateMask(riverMask).unmask(0)\n",
        "bn = ee.List(quantileImage.bandNames()).map(appendStringFlag)\n",
        "reducer = ee.Reducer.anyNonZero().forEach(bn)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3W_I8JFuHZm"
      },
      "source": [
        "collection = fc_3spc.map(filt_lines)\n",
        "fc_3spc = collection.filter(ee.Filter.eq('geo_type', 'LineString'))\n",
        "\n",
        "#fc_3spc = fc_3spc.filterBounds(rc_roi)\n",
        "LT5_BANDS = ['B1',   'B2',    'B3',  'B4',  'B5',    'B7',    'B6'];\n",
        "LE7_BANDS = ['B1',   'B2',    'B3',  'B4',  'B5',    'B7',    'B6'];\n",
        "LC8_BANDS = ['B2',   'B3',    'B4',  'B5',  'B6',    'B7',    'B10'];\n",
        "STD_NAMES = ['Blue', 'Green', 'Red', 'Nir', 'Swir1', 'Swir2', 'Temp'];\n",
        "\n",
        "#// load Landsat 5,7,8 collections:\n",
        "#// TODO(GHA): combine 5, 7, and 8 collections:\n",
        "LT5 = ee.ImageCollection('LANDSAT/LT5_L1T_SR').select(LT5_BANDS, STD_NAMES);\n",
        "LT5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR').select(LT5_BANDS, STD_NAMES); \n",
        "LE7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR').select(LE7_BANDS, STD_NAMES).filterDate('1999-01-01', '2003-05-30')\n",
        "##.select(LE7_BANDS, STD_NAMES);\n",
        "LC8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').select(LC8_BANDS, STD_NAMES);\n",
        "\n",
        "collection = LC8.merge(LT5).merge(LE7)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiI1ybHfuSpi"
      },
      "source": [
        "p = [1576000,\n",
        "15453500,\n",
        "6764000,\n",
        "6132000,\n",
        "2198375,\n",
        "7374000,\n",
        "7229200,\n",
        "12438000,\n",
        "12396500,\n",
        "3399800,\n",
        "6177000,\n",
        "2171645,\n",
        "5133500,\n",
        "6078200,\n",
        "6478500,\n",
        "12200500,\n",
        "15303900,\n",
        "5536890,\n",
        "5586100,\n",
        "7381490,\n",
        "3216600,\n",
        "7032000,\n",
        "7146500,\n",
        "13172500,\n",
        "12462600,\n",
        "12472800,\n",
        "9380000,\n",
        "3431500,\n",
        "7165570,\n",
        "5442300]\n",
        "\n",
        "#p = [6078200]\n",
        "\n",
        "##First set. \n",
        "p1 = [2427500,\n",
        "5404000,\n",
        "5441500,\n",
        "5339500,\n",
        "15389100,\n",
        "2359170,\n",
        "12318500,\n",
        "2358700,\n",
        "5398000,\n",
        "5427530,\n",
        "5331580,\n",
        "3417500,\n",
        "2358000,\n",
        "2343801,\n",
        "3342000,\n",
        "9315000,\n",
        "7359001,\n",
        "2218500,\n",
        "3072500,\n",
        "12392000,\n",
        "1515050,\n",
        "15056500,\n",
        "7302000,\n",
        "1540500,\n",
        "2102500,\n",
        "1434000,\n",
        "1154500,\n",
        "12353000,\n",
        "2489000,\n",
        "7074500]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfPbQCe3uZv9"
      },
      "source": [
        "distFilter = ee.Filter.contains(\n",
        "  leftField ='.geo',\n",
        "  rightField = '.geo'\n",
        "  )\n",
        "\n",
        "ee.Filter.contains()\n",
        "\n",
        "distSaveAll = ee.Join.saveAll(\n",
        "    matchesKey ='points',\n",
        "    measureKey = 'distance');\n",
        "\n",
        "\n",
        "  \n",
        "def ij (state):\n",
        "  nPowerPlants = ee.List(state.get('points'))\n",
        "  mean = ee.FeatureCollection(nPowerPlants).aggregate_mean('width_m')\n",
        "  return ee.FeatureCollection(state.set({'width_m': mean}))\n",
        "\n",
        "\n",
        "def connected (f):\n",
        "  con = f.clip(buff1) ####changed this from f.clipToBoundsAndScale(filt) &&& changed from polygon to buff1\n",
        "  return con\n",
        "\n",
        "def grwl_filter_fun (f):\n",
        "  con = f.clip(polygon)\n",
        "  return con\n",
        "\n",
        "\n",
        "##Changed f.eq(1) to f.\n",
        "def effective_width_1 (f):                     \n",
        "  lng = (f.reduceRegions(\n",
        "  collection= grwl_cline.filterBounds(filt), \n",
        "  reducer= ee.Reducer.count(),\n",
        "  ))\n",
        "  return lng \n",
        "\n",
        "\n",
        "##Changed collection = fi1.flatten().geometry()  & con.select('channelMask').eq(1)\n",
        "def effective_width_2 (con):\n",
        "  sum = (con.select('channelMask').eq(1).reduceRegions(\n",
        "  collection= buff1, ##changed from polygon \n",
        "  reducer= ee.Reducer.sum().unweighted(),  ##Unweighted added for flagging technique. \n",
        "  ))\n",
        "  return sum\n",
        "\n",
        "##changed from 22\n",
        "def Area_fun (feature):\n",
        "  d = ee.Number(feature.get('sum'))\n",
        "  id = feature.getString('system:index').slice(0,24)\n",
        "  return feature.set({'Area': ee.Number(d).multiply(900), 'id': id})\n",
        "\n",
        "\n",
        "##changed from 22\n",
        "def len_fun (feature):\n",
        "  d = ee.Number(feature.get('count'))\n",
        "  id = feature.getString('system:index').slice(0,24)\n",
        "  return feature.set({'length': ee.Number(d).multiply(30), 'id':id})\n",
        "\n",
        "toyFilter = ee.Filter.equals(leftField = 'id',\n",
        "                             rightField ='id');\n",
        "\n",
        "\n",
        "innerJoin = ee.Join.inner()\n",
        "\n",
        "\n",
        "def fc_function (f):\n",
        "  p = ee.Feature(f.get('primary'))\n",
        "  s = ee.Feature(f.get('secondary'))\n",
        "  properties = p.copyProperties(s)\n",
        "  return properties\n",
        "\n",
        "\n",
        "def effW_fun (feature):\n",
        "  Area = ee.Number(feature.get('Area'))\n",
        "  Length = ee.Number(feature.get('length'))\n",
        "  return feature.set({'Effective_width': Area.divide(Length)})\n",
        "\n",
        "\n",
        "##'COMID': distinct_comid.first().get('COMID')\n",
        "def fields (f):\n",
        "  return f.set({'width_m':intersectJoined.flatten().first().get('width_m'), 'ID': fc_id.first().get('ID_2')})\n",
        "\n",
        "\n",
        "def set_id (f):\n",
        "  return f.set({'id': fc_id})\n",
        "\n",
        "\n",
        "#Changed collection from pts\n",
        "def flagging (f):\n",
        "  a = (f.reduceRegions(\n",
        "      collection = pts.geometry(),\n",
        "      reducer = ee.Reducer.max(),\n",
        "  ))\n",
        "  return a\n",
        "##changed from 22\n",
        "def flagged_collection_fun (f):\n",
        "  id = f.getString('system:index').slice(0,24)\n",
        "  return f.set({'id': id})\n",
        "\n",
        "\n",
        "\n",
        "def feature_fun (f):\n",
        "  a = ee.Geometry.Point(f)\n",
        "  b = ee.Feature(a, {'id': 1, 'e/o':2})\n",
        "  return(b)\n",
        "\n",
        "def id_fun (f):\n",
        "  a = f.get('system:index')\n",
        "  b = f.set({'id': a})\n",
        "  return(b)\n",
        "def getOddNumbers (f):\n",
        "  number = ee.Number.parse(f.get('id'))\n",
        "  remainder = number.mod(2)\n",
        "  val = number.multiply(remainder)\n",
        "  c = f.set({'e/o':val})\n",
        "  return(c)\n",
        "\n",
        "def farthest_distance_function (f):\n",
        "  a = ee.Feature(f).distance(ee.Feature(farthest_pt))\n",
        "  b = f.set('distance', a)\n",
        "  return(b)\n",
        "\n",
        "def farthest_distance_function_even (f):\n",
        "  a = ee.Feature(f).distance(ee.Feature(farthest_even))\n",
        "  b = f.set('distance', a)\n",
        "  return(b)\n",
        "\n",
        "def comid_fun (f):\n",
        "  #a = 'COMID{}'.format(f)##.slice(0,6)\n",
        "  a = str(f)\n",
        "  return a\n",
        "\n",
        "def difference_fun (f):\n",
        "  p = ee.Feature(f.get('primary'))\n",
        "  a = ee.Number(p.get('Area'))\n",
        "  s = ee.Feature(f.get('secondary'))\n",
        "  b = ee.Number(s.get('Area'))\n",
        "  return s.set({'Difference': a.subtract(b)})\n",
        "\n",
        "def change_fun (f):\n",
        "  a = median_change.get('change_abs')\n",
        "  b = f.set({'change':a})\n",
        "  b = b.set(comid_dict)\n",
        "  return b\n",
        "\n",
        "\n",
        "\n",
        "def MaskFunction (f):\n",
        "  a = f.eq(1)\n",
        "  b = f.mask(a)\n",
        "  return b"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19vbGRo2I31W",
        "outputId": "333f2c83-b7e4-4222-a373-4eed554cb858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##GRWL_buffer\n",
        "for i in range(len(p)):\n",
        "  filter_gauge = gauges.filter(ee.Filter.eq('SITE_NUM', p[i]))\n",
        "  buff1 = filter_gauge.map(buffer_zone)\n",
        "  fi1 = buff1.map(ftr_coll)\n",
        "  filt1 = fc_3spc.filterBounds(fi1.flatten().geometry())\n",
        "  \n",
        "  fff = filt1.map(distance_fun)\n",
        "  filt = fff.filter(ee.Filter.lte('distance', 1000))\n",
        "  fc_id = filt.limit(1, 'distance')\n",
        "  \n",
        "  grwl_filt = grwl_cline.filterBounds(filt)\n",
        "  grwl_filt_geom = grwl_filt.geometry().buffer(grwl_filt.first().get('width_mean'))\n",
        "\n",
        "  intersect = grwl_filt_geom.intersection(buff1)\n",
        "  polygon = intersect\n",
        "  spatialJoined = distSaveAll.apply(fi1.flatten(), filt, distFilter);\n",
        "  distinct_comid = filt1.filterBounds(polygon).sort('distance').distinct('COMID')\n",
        "  distinct_comid = distinct_comid.reduceColumns(ee.Reducer.toList(), ['COMID'])\n",
        "  distinct_length = ee.List(distinct_comid.get('list'))\n",
        "  numb_comid = distinct_length.size()\n",
        "\n",
        "  n = numb_comid.getInfo()\n",
        "\n",
        "  seq = list(range(0, n))\n",
        "  seq = ['COMID'+str(i) for i in seq]\n",
        "\n",
        "  print(seq)\n",
        "  #comid_seq = seq.map(comid_fun)\n",
        "  comid_dict = ee.Dictionary.fromLists(seq, distinct_length)\n",
        "\n",
        "\n",
        "  intersectJoined = spatialJoined.map(ij)\n",
        "  fi1 = intersectJoined\n",
        "  \n",
        "  #filt = fc_3spc.filterBounds(x1)\n",
        "  filtered = collection.filterDate('1984-01-01', '2020-12-31').sort('system:time_start').filterMetadata('CLOUD_COVER', 'less_than', 10).filterBounds(filt)\n",
        "  filt_con = filtered.map(connected)\n",
        "  filtered = filt_con\n",
        "  waterMask = filtered.map(ClassifyWaterJones2019)\n",
        "  GetCenterline(grwl_cline, filt)\n",
        "  riverMask = waterMask.map(ExtractChannel)\n",
        "\n",
        "  connected_mask = riverMask#.map(connected)\n",
        "  connected_test = connected_mask.map(grwl_filter_fun)\n",
        "\n",
        "\n",
        "\n",
        "  eff_width1 = connected_test.map(effective_width_1)\n",
        "\n",
        "  connected_test = connected_test.map(MaskFunction)\n",
        "  connected_mask = connected_mask.map(MaskFunction)\n",
        "\n",
        "  eff_width2 = connected_test.map(effective_width_2)\n",
        "  \n",
        "  eff_width2_filt = connected_mask.map(effective_width_2)\n",
        "  circle = eff_width2_filt.flatten().map(Area_fun)\n",
        "  area_map = eff_width2.flatten().map(Area_fun)\n",
        "  len_map = eff_width1.flatten().map(len_fun)\n",
        "  toyJoin = innerJoin.apply(area_map, len_map,  toyFilter)\n",
        "  fc_test = toyJoin.map(fc_function)\n",
        "\n",
        "  difference = innerJoin.apply(circle, fc_test, toyFilter)\n",
        "  diff_t = difference.map(difference_fun)\n",
        "\n",
        "  fc_test = diff_t\n",
        "\n",
        "\n",
        "  testing = fc_test.map(effW_fun)\n",
        "  fields_vals = testing.map(fields)\n",
        "  selection = fields_vals.select(['Effective_width', 'ID', 'id', 'COMID', 'width_m', 'Difference'])\n",
        "  sel = selection.filter(ee.Filter.gt('Effective_width', 0))\n",
        "  selection = sel\n",
        "  \n",
        "  median_change = change.reduceRegion(ee.Reducer.median(), polygon)\n",
        "  \n",
        "  selection = selection.map(change_fun)\n",
        "\n",
        "  #selection = selection.distinct('id')\n",
        "\n",
        "  task = (ee.batch.Export.table.toDrive(\n",
        "  collection = selection,\n",
        "  description = 'widths_' + '_' + str(p[i]),\n",
        "  folder = 'Effective_widths_buffered_cline_flagged',\n",
        "  fileNamePrefix = 'Gauge_' + '_' + str(p[i]),\n",
        "  fileFormat = 'csv'\n",
        "  ))\n",
        "\n",
        "  task.start()\n",
        "#print(output.first())\n",
        "  print('task', i, 'has started')\n",
        "  maximum_no_of_tasks(3, 60)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['COMID0', 'COMID1', 'COMID2', 'COMID3', 'COMID4']\n",
            "task 0 has started\n",
            "['COMID0', 'COMID1', 'COMID2', 'COMID3', 'COMID4']\n",
            "task 1 has started\n",
            "['COMID0']\n",
            "task 2 has started\n",
            "['COMID0', 'COMID1', 'COMID2']\n",
            "task 3 has started\n",
            "['COMID0']\n",
            "task 4 has started\n",
            "['COMID0']\n",
            "task 5 has started\n",
            "['COMID0']\n",
            "task 6 has started\n",
            "['COMID0', 'COMID1', 'COMID2']\n",
            "task 7 has started\n",
            "['COMID0']\n",
            "task 8 has started\n",
            "['COMID0', 'COMID1', 'COMID2', 'COMID3', 'COMID4']\n",
            "task 9 has started\n",
            "['COMID0']\n",
            "task 10 has started\n",
            "['COMID0']\n",
            "task 11 has started\n",
            "['COMID0']\n",
            "task 12 has started\n",
            "['COMID0']\n",
            "task 13 has started\n",
            "['COMID0', 'COMID1', 'COMID2', 'COMID3', 'COMID4', 'COMID5', 'COMID6']\n",
            "task 14 has started\n",
            "['COMID0']\n",
            "task 15 has started\n",
            "['COMID0', 'COMID1', 'COMID2']\n",
            "task 16 has started\n",
            "['COMID0']\n",
            "task 17 has started\n",
            "['COMID0']\n",
            "task 18 has started\n",
            "['COMID0']\n",
            "task 19 has started\n",
            "['COMID0']\n",
            "task 20 has started\n",
            "['COMID0', 'COMID1', 'COMID2']\n",
            "task 21 has started\n",
            "['COMID0']\n",
            "task 22 has started\n",
            "['COMID0']\n",
            "task 23 has started\n",
            "['COMID0', 'COMID1']\n",
            "task 24 has started\n",
            "['COMID0']\n",
            "task 25 has started\n",
            "['COMID0', 'COMID1', 'COMID2', 'COMID3']\n",
            "task 26 has started\n",
            "['COMID0']\n",
            "task 27 has started\n",
            "['COMID0', 'COMID1', 'COMID2']\n",
            "task 28 has started\n",
            "['COMID0']\n",
            "task 29 has started\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frwSPlOPuaHo"
      },
      "source": [
        "#################### Calculate quantile widths for each gauge/scene. \n",
        "for i in range(len(p)):\n",
        "  filter_gauge = gauges.filter(ee.Filter.eq('SITE_NUM', p[i])) ##'SITE_NUM' changed to 'Sttn_Nm'\n",
        "  buff1 = filter_gauge.map(buffer_zone)\n",
        "  fi1 = buff1.map(ftr_coll)\n",
        "  filt1 = fc_3spc.filterBounds(fi1.flatten().geometry())\n",
        "  fff = filt1.map(distance_fun)\n",
        "\n",
        "  fff = filt1.map(distance_fun)\n",
        "  filt = fff.filter(ee.Filter.lte('distance', 1000))\n",
        "  fc_id = fff.limit(1, 'distance')\n",
        "  fc_id = fc_id.first().get('ID_2')\n",
        "  spatialJoined = distSaveAll.apply(fi1.flatten(), filt, distFilter);\n",
        "  distinct_comid = filt.distinct('COMID')\n",
        "  intersectJoined = spatialJoined.map(ij)\n",
        "  fi1 = intersectJoined\n",
        "\n",
        "  fi1 = intersectJoined.set({'COMID': distinct_comid.first().get('COMID'), 'width_m':intersectJoined.flatten().first().get('width_m')})\n",
        "\n",
        "  quantileImage_f = connected(quantileImage)\n",
        "\n",
        "  Area = (quantileImage_f\n",
        "  .addBands(nobs.rename(['n_valid_obs']))\n",
        "  .reduceRegions(\n",
        "  collection= fi1.flatten().geometry(), \n",
        "  reducer= ee.Reducer.sum(),\n",
        "  scale = 30,\n",
        "  crs = 'EPSG:4326',\n",
        "  tileScale = 1\n",
        "  ))\n",
        "\n",
        "  length = (quantileImage_f\n",
        "  .addBands(nobs.rename(['n_valid_obs']))\n",
        "  .reduceRegions(\n",
        "  collection= grwl_cline.filterBounds(filt), \n",
        "  reducer= ee.Reducer.count(),\n",
        "  scale = 30,\n",
        "  crs = 'EPSG:4326',\n",
        "  tileScale = 1\n",
        "  ))\n",
        "\n",
        "  Area = Area.map(set_id)\n",
        "  length = length.map(set_id)\n",
        "\n",
        "  #Area = Area.set\n",
        "\n",
        "  #length = set_id(length)\n",
        "\n",
        "  #result = innerJoin.apply(Area, length, toyFilter)\n",
        "  #result = result.map(fc_function)\n",
        "    # export widths\n",
        "  task = (ee.batch.Export.table.toDrive(\n",
        "  collection = length,\n",
        "  description = 'Canada' + '_' + str(p[i]),\n",
        "  folder = 'Effective_width_quantiles',\n",
        "  fileNamePrefix = 'length_' + '_' + str(p[i]),\n",
        "  fileFormat = 'csv'\n",
        "  ))\n",
        "  task.start()\n",
        "\n",
        "  # task = (ee.batch.Export.table.toDrive(\n",
        "  # collection = length,\n",
        "  # description = 'Canada' + '_' + str(p[i]),\n",
        "  # folder = 'Effective_width_quantiles',\n",
        "  # fileNamePrefix = 'length_' + '_' + str(p[i]),\n",
        "  # fileFormat = 'csv'\n",
        "  # ))\n",
        "  # task.start()\n",
        "#print(output.first())\n",
        "  print('task', i, 'has started')\n",
        "  maximum_no_of_tasks(3, 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkLBxJKgwyjS"
      },
      "source": [
        "####### Calculate widths for each gauge in list p unchanged. \n",
        "for i in range(len(p)):\n",
        "  filter_gauge = gauges.filter(ee.Filter.eq('SITE_NUM', p[i]))\n",
        "  buff1 = filter_gauge.map(buffer_zone)\n",
        "  fi1 = buff1.map(ftr_coll)\n",
        "  filt1 = fc_3spc.filterBounds(fi1.flatten().geometry())\n",
        "  \n",
        "  fff = filt1.map(distance_fun)\n",
        "  filt = fff.filter(ee.Filter.lte('distance', 1000))\n",
        "  fc_id = fff.limit(1, 'distance')\n",
        "  spatialJoined = distSaveAll.apply(fi1.flatten(), filt, distFilter);\n",
        "  distinct_comid = filt.distinct('COMID')\n",
        "  intersectJoined = spatialJoined.map(ij)\n",
        "  fi1 = intersectJoined\n",
        "  \n",
        "  #filt = fc_3spc.filterBounds(x1)\n",
        "  filtered = collection.filterDate('1984-01-01', '2020-12-31').sort('system:time_start').filterMetadata('CLOUD_COVER', 'less_than', 10).filterBounds(filt)\n",
        "  waterMask = filtered.map(ClassifyWaterJones2019)\n",
        "  GetCenterline(grwl_cline, filt)\n",
        "  riverMask = waterMask.map(ExtractChannel)\n",
        "  connected_mask = riverMask.map(connected)\n",
        "  eff_width1 = connected_mask.map(effective_width_1)\n",
        "  eff_width2 = connected_mask.map(effective_width_2)\n",
        "  area_map = eff_width2.flatten().map(Area_fun)\n",
        "  len_map = eff_width1.flatten().map(len_fun)\n",
        "  toyJoin = innerJoin.apply(area_map, len_map,  toyFilter)\n",
        "  fc_test = toyJoin.map(fc_function)\n",
        "  testing = fc_test.map(effW_fun)\n",
        "  fields_vals = testing.map(fields)\n",
        "  selection = fields_vals.select(['Effective_width', 'ID', 'id', 'COMID', 'width_m'])\n",
        "\n",
        "  task = (ee.batch.Export.table.toDrive(\n",
        "  collection = selection,\n",
        "  description = 'widths_' + '_' + str(p[i]),\n",
        "  folder = 'Effective_widths_unchanged',\n",
        "  fileNamePrefix = 'Gauge_' + '_' + str(p[i]),\n",
        "  fileFormat = 'csv'\n",
        "  ))\n",
        "\n",
        "  task.start()\n",
        "#print(output.first())\n",
        "  print('task', i, 'has started')\n",
        "  maximum_no_of_tasks(3, 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV7CL7opN_ht"
      },
      "source": [
        "##More indepth polygon\n",
        "for i in range(len(p)):\n",
        "  filter_gauge = gauges.filter(ee.Filter.eq('SITE_NUM', p[i]))\n",
        "  buff1 = filter_gauge.map(buffer_zone)\n",
        "  fi1 = buff1.map(ftr_coll)\n",
        "  filt1 = fc_3spc.filterBounds(fi1.flatten().geometry())\n",
        "  \n",
        "  fff = filt1.map(distance_fun)\n",
        "  filt = fff.filter(ee.Filter.lte('distance', 500))\n",
        "  fc_id = filt.limit(1, 'distance')\n",
        "  \n",
        "  pts = filt.map(switchGeometryLine2Endpoints).sort('distance', False)\n",
        "  pts_col = pts.geometry().coordinates()\n",
        "  fc = pts_col.map(feature_fun)\n",
        "  fc = ee.FeatureCollection(fc)\n",
        "  id = fc.map(id_fun)\n",
        "  newList = id.map(getOddNumbers)\n",
        "  oddNumbers = newList.filter(ee.Filter.eq('e/o', 0))\n",
        "  farthest_pt = oddNumbers.first()\n",
        "  oddNumbers = oddNumbers.map(farthest_distance_function).sort('distance')\n",
        "  evenNumbers = newList.filter(ee.Filter.neq('e/o', 0))\n",
        "  farthest_even = evenNumbers.first()\n",
        "  evenNumbers = evenNumbers.map(farthest_distance_function_even).sort('distance', False)\n",
        "  evenNumbers = evenNumbers.geometry().coordinates()\n",
        "  evenNumbers = evenNumbers.map(feature_fun)\n",
        "  combining = oddNumbers.merge(evenNumbers)\n",
        "  geom = ee.Geometry.Polygon(combining.geometry().coordinates())\n",
        "\n",
        "  polygon = geom\n",
        "\n",
        "\n",
        "  spatialJoined = distSaveAll.apply(fi1.flatten(), filt, distFilter);\n",
        "  distinct_comid = filt.distinct('COMID')\n",
        "  intersectJoined = spatialJoined.map(ij)\n",
        "  fi1 = intersectJoined\n",
        "  \n",
        "  #filt = fc_3spc.filterBounds(x1)\n",
        "  filtered = collection.filterDate('1984-01-01', '2020-12-31').sort('system:time_start').filterMetadata('CLOUD_COVER', 'less_than', 10).filterBounds(filt)\n",
        "  filt_con = filtered.map(connected)\n",
        "  filtered = filt_con\n",
        "  waterMask = filtered.map(ClassifyWaterJones2019)\n",
        "  GetCenterline(grwl_cline, filt)\n",
        "  riverMask = waterMask.map(ExtractChannel)\n",
        "  #connected_mask = riverMask.map(connected)\n",
        "  connected_mask = riverMask\n",
        "  flagged_coll = connected_mask.map(flagging)\n",
        "  flagged_coll = flagged_coll.flatten().map(flagged_collection_fun)\n",
        "\n",
        "  eff_width1 = connected_mask.map(effective_width_1)\n",
        "  eff_width2 = connected_mask.map(effective_width_2)\n",
        "  area_map = eff_width2.flatten().map(Area_fun)\n",
        "  len_map = eff_width1.flatten().map(len_fun)\n",
        "  toyJoin = innerJoin.apply(area_map, len_map,  toyFilter)\n",
        "  fc_test = toyJoin.map(fc_function)\n",
        "  testing = fc_test.map(effW_fun)\n",
        "  flagged_test = innerJoin.apply(testing, flagged_coll, toyFilter)\n",
        "  \n",
        "  eff_widths_flags = flagged_test.map(fc_function)\n",
        "  testing = eff_widths_flags.distinct('id')\n",
        "\n",
        "  fields_vals = testing.map(fields)\n",
        "  selection = fields_vals.select(['Effective_width', 'ID', 'id', 'COMID', 'width_m', 'max'])\n",
        "\n",
        "  sel = selection.filter(ee.Filter.gt('Effective_width', 0))\n",
        "  select = sel.filter(ee.Filter.eq('max', 0))\n",
        "  selection = select\n",
        "\n",
        "  task = (ee.batch.Export.table.toDrive(\n",
        "  collection = selection,\n",
        "  description = 'widths_' + '_' + str(p[i]),\n",
        "  folder = 'Effective_widths_flagging_Polygon_xsections_500m',\n",
        "  fileNamePrefix = 'Gauge_' + '_' + str(p[i]),\n",
        "  fileFormat = 'csv'\n",
        "  ))\n",
        "\n",
        "  task.start()\n",
        "#print(output.first())\n",
        "  print('task', i, 'has started')\n",
        "  maximum_no_of_tasks(3, 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl_orrI2OC3O",
        "outputId": "5d25150b-e8cc-47a5-baa3-95409e37e0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "####### Calculate widths for each gauge in list p unchanged. Add in flagging method and change how polygon is drawn and clipped. \n",
        "for i in range(len(p)):\n",
        "  filter_gauge = gauges.filter(ee.Filter.eq('SITE_NUM', p[i]))\n",
        "  buff1 = filter_gauge.map(buffer_zone)\n",
        "  fi1 = buff1.map(ftr_coll)\n",
        "  filt1 = fc_3spc.filterBounds(fi1.flatten().geometry())\n",
        "  \n",
        "  fff = filt1.map(distance_fun)\n",
        "  filt = fff.filter(ee.Filter.lte('distance', 2000))\n",
        "  fc_id = filt.limit(1, 'distance')\n",
        "  far = filt.limit(1, 'distance', False)\n",
        "  poly_d = filt.map(distance_fun_poly)\n",
        "  other = poly_d.limit(1, 'distance_1', False)\n",
        "  combined = far.merge(other)\n",
        "  pts = combined.map(switchGeometryLine2Endpoints)\n",
        "  pts_col = pts.geometry().coordinates()\n",
        "  pts_col = pts_col.swap(0,1)\n",
        "  polygon = ee.Geometry.Polygon(pts_col)\n",
        "\n",
        "\n",
        "  spatialJoined = distSaveAll.apply(fi1.flatten(), filt, distFilter);\n",
        "  distinct_comid = filt.distinct('COMID')\n",
        "  intersectJoined = spatialJoined.map(ij)\n",
        "  fi1 = intersectJoined\n",
        "  \n",
        "  #filt = fc_3spc.filterBounds(x1)\n",
        "  filtered = collection.filterDate('1984-01-01', '2020-12-31').sort('system:time_start').filterMetadata('CLOUD_COVER', 'less_than', 10).filterBounds(filt)\n",
        "  filt_con = filtered.map(connected)\n",
        "  filtered = filt_con\n",
        "  waterMask = filtered.map(ClassifyWaterJones2019)\n",
        "  GetCenterline(grwl_cline, filt)\n",
        "  riverMask = waterMask.map(ExtractChannel)\n",
        "  #connected_mask = riverMask.map(connected)\n",
        "  connected_mask = riverMask\n",
        "  flagged_coll = connected_mask.map(flagging)\n",
        "  flagged_coll = flagged_coll.flatten().map(flagged_collection_fun)\n",
        "\n",
        "  eff_width1 = connected_mask.map(effective_width_1)\n",
        "  eff_width2 = connected_mask.map(effective_width_2)\n",
        "  area_map = eff_width2.flatten().map(Area_fun)\n",
        "  len_map = eff_width1.flatten().map(len_fun)\n",
        "  toyJoin = innerJoin.apply(area_map, len_map,  toyFilter)\n",
        "  fc_test = toyJoin.map(fc_function)\n",
        "  testing = fc_test.map(effW_fun)\n",
        "  flagged_test = innerJoin.apply(testing, flagged_coll, toyFilter)\n",
        "  \n",
        "  eff_widths_flags = flagged_test.map(fc_function)\n",
        "  testing = eff_widths_flags.distinct('id')\n",
        "\n",
        "  fields_vals = testing.map(fields)\n",
        "  selection = fields_vals.select(['Effective_width', 'ID', 'id', 'COMID', 'width_m', 'max'])\n",
        "\n",
        "  sel = selection.filter(ee.Filter.gt('Effective_width', 0))\n",
        "  select = sel.filter(ee.Filter.eq('max', 0))\n",
        "  selection = select\n",
        "\n",
        "  task = (ee.batch.Export.table.toDrive(\n",
        "  collection = selection,\n",
        "  description = 'widths_' + '_' + str(p[i]),\n",
        "  folder = 'Effective_widths_flagging_updated_Poly_2km',\n",
        "  fileNamePrefix = 'Gauge_' + '_' + str(p[i]),\n",
        "  fileFormat = 'csv'\n",
        "  ))\n",
        "\n",
        "  task.start()\n",
        "#print(output.first())\n",
        "  print('task', i, 'has started')\n",
        "  maximum_no_of_tasks(3, 60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task 0 has started\n",
            "task 1 has started\n",
            "task 2 has started\n",
            "task 3 has started\n",
            "task 4 has started\n",
            "task 5 has started\n",
            "task 6 has started\n",
            "task 7 has started\n",
            "task 8 has started\n",
            "task 9 has started\n",
            "task 10 has started\n",
            "task 11 has started\n",
            "task 12 has started\n",
            "task 13 has started\n",
            "task 14 has started\n",
            "task 15 has started\n",
            "task 16 has started\n",
            "task 17 has started\n",
            "task 18 has started\n",
            "task 19 has started\n",
            "task 20 has started\n",
            "task 21 has started\n",
            "task 22 has started\n",
            "task 23 has started\n",
            "task 24 has started\n",
            "task 25 has started\n",
            "task 26 has started\n",
            "task 27 has started\n",
            "task 28 has started\n",
            "task 29 has started\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}